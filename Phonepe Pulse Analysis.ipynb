{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c18f380",
   "metadata": {},
   "source": [
    "### Importing necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30be3da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a132f1",
   "metadata": {},
   "source": [
    "### Cloning from repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf4bfb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Projects\\Phonepe_pulse\\Miscellaneous\\Pulse\\data\n"
     ]
    }
   ],
   "source": [
    "repo_url = \"https://github.com/PhonePe/pulse.git\"\n",
    "clone_path = r\"C:\\ProgramFiles\\Projects\\Phonepe_pulse\\Miscellaneous\"\n",
    "\n",
    "if not os.path.exists(clone_path):\n",
    "    os.makedirs(clone_path)\n",
    "\n",
    "repo_path = os.path.join(clone_path, os.path.basename(repo_url).removesuffix('.git').title())\n",
    "\n",
    "Repo.clone_from(repo_url, repo_path)\n",
    "\n",
    "directory = os.path.join(repo_path, 'data')\n",
    "print(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3522e5f5",
   "metadata": {},
   "source": [
    "### Renaming sub-directories and Extracting necessary paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d013a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to rename messy state names in a proper format\n",
    "\n",
    "def rename(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        if 'state' in dirs:\n",
    "            state_dir = os.path.join(root, 'state')\n",
    "            for state_folder in os.listdir(state_dir):\n",
    "                # rename the state folder\n",
    "                old_path = os.path.join(state_dir, state_folder)\n",
    "                new_path = os.path.join(state_dir, state_folder.title().replace('-', ' ').replace('&', 'and'))\n",
    "                os.rename(old_path, new_path)\n",
    "    print(\"Renamed all sub-directories successfully\")\n",
    "                \n",
    "# Function to extract all paths that has sub-directory in the name of 'state'\n",
    "\n",
    "def extract_paths(directory):\n",
    "    path_list = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        if os.path.basename(root) == 'state':\n",
    "            path_list.append(root.replace('\\\\', '/'))\n",
    "    return path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2312097d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed all sub-directories successfully\n"
     ]
    }
   ],
   "source": [
    "rename(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "579206c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/ProgramFiles/Projects/Phonepe_pulse/Miscellaneous/Pulse/data/aggregated/transaction/country/india/state',\n",
       " 'C:/ProgramFiles/Projects/Phonepe_pulse/Miscellaneous/Pulse/data/aggregated/user/country/india/state',\n",
       " 'C:/ProgramFiles/Projects/Phonepe_pulse/Miscellaneous/Pulse/data/map/transaction/hover/country/india/state',\n",
       " 'C:/ProgramFiles/Projects/Phonepe_pulse/Miscellaneous/Pulse/data/map/user/hover/country/india/state',\n",
       " 'C:/ProgramFiles/Projects/Phonepe_pulse/Miscellaneous/Pulse/data/top/transaction/country/india/state',\n",
       " 'C:/ProgramFiles/Projects/Phonepe_pulse/Miscellaneous/Pulse/data/top/user/country/india/state']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_directories = extract_paths(directory)\n",
    "state_directories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec32256",
   "metadata": {},
   "source": [
    "### Creating dataframes from cloned json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e484d601",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_path = state_directories[0]\n",
    "state_list = os.listdir(state_path)\n",
    "agg_trans_dict = {\n",
    "                  'State': [], 'Year': [], 'Quarter': [], 'Transaction_type': [],\n",
    "                  'Transaction_count': [], 'Transaction_amount': []\n",
    "                  }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        quarter_path = year_path + year + '/'\n",
    "        quarter_list = os.listdir(quarter_path)\n",
    "        \n",
    "        for quarter in quarter_list:\n",
    "            json_path = quarter_path + quarter\n",
    "            df = pd.read_json(json_path)\n",
    "            \n",
    "            try:\n",
    "                for transaction_data in df['data']['transactionData']:\n",
    "                    \n",
    "                    type = transaction_data['name']\n",
    "                    count = transaction_data['paymentInstruments'][0]['count']\n",
    "                    amount = transaction_data['paymentInstruments'][0]['amount']\n",
    "                    \n",
    "                    # Appending to agg_trans_dict\n",
    "                    \n",
    "                    agg_trans_dict['State'].append(state)\n",
    "                    agg_trans_dict['Year'].append(year)\n",
    "                    agg_trans_dict['Quarter'].append(int(quarter.removesuffix('.json')))\n",
    "                    agg_trans_dict['Transaction_type'].append(type)\n",
    "                    agg_trans_dict['Transaction_count'].append(count)\n",
    "                    agg_trans_dict['Transaction_amount'].append(amount)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "agg_trans_df = pd.DataFrame(agg_trans_dict)\n",
    "\n",
    "# 2. Aggregate user\n",
    "\n",
    "state_path = state_directories[1]\n",
    "state_list = os.listdir(state_path)\n",
    "agg_user_dict = {\n",
    "                 'State': [], 'Year': [], 'Quarter': [], 'Brand': [],\n",
    "                 'Transaction_count': [], 'Percentage': []\n",
    "                 }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        quarter_path = year_path + year + '/'\n",
    "        quarter_list = os.listdir(quarter_path)\n",
    "        \n",
    "        for quarter in quarter_list:\n",
    "            json_path = quarter_path + quarter\n",
    "            df = pd.read_json(json_path)\n",
    "            \n",
    "            try:\n",
    "                for user_data in df['data']['usersByDevice']:\n",
    "\n",
    "                    brand = user_data['brand']\n",
    "                    count = user_data['count']\n",
    "                    percent = user_data['percentage']\n",
    "                    \n",
    "                    # Appending to agg_user_dict\n",
    "                    \n",
    "                    agg_user_dict['State'].append(state)\n",
    "                    agg_user_dict['Year'].append(year)\n",
    "                    agg_user_dict['Quarter'].append(int(quarter.removesuffix('.json')))\n",
    "                    agg_user_dict['Brand'].append(brand)\n",
    "                    agg_user_dict['Transaction_count'].append(count)\n",
    "                    agg_user_dict['Percentage'].append(percent)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "agg_user_df = pd.DataFrame(agg_user_dict)\n",
    "\n",
    "# 3. Map Transaction\n",
    "\n",
    "state_path = state_directories[2]\n",
    "state_list = os.listdir(state_path)\n",
    "map_trans_dict = {\n",
    "                    'State': [], 'Year': [], 'Quarter': [], 'District': [],\n",
    "                    'Transaction_count': [], 'Transaction_amount': []\n",
    "                    }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        quarter_path = year_path + year + '/'\n",
    "        quarter_list = os.listdir(quarter_path)\n",
    "        \n",
    "        for quarter in quarter_list:\n",
    "            json_path = quarter_path + quarter\n",
    "            df = pd.read_json(json_path)\n",
    "            \n",
    "            try:\n",
    "                for transaction_data in df['data']['hoverDataList']:\n",
    "                   \n",
    "                    district = transaction_data['name']\n",
    "                    count = transaction_data['metric'][0]['count']\n",
    "                    amount = transaction_data['metric'][0]['amount']\n",
    "                    \n",
    "                    # Appending to map_trans_dict\n",
    "                    \n",
    "                    map_trans_dict['State'].append(state)\n",
    "                    map_trans_dict['Year'].append(year)\n",
    "                    map_trans_dict['Quarter'].append(int(quarter.removesuffix('.json'))) \n",
    "                    map_trans_dict['District'].append(district.removesuffix(' district').title().replace(' And', ' and').replace('andaman', 'Andaman'))\n",
    "                    map_trans_dict['Transaction_count'].append(count)\n",
    "                    map_trans_dict['Transaction_amount'].append(amount)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "map_trans_df = pd.DataFrame(map_trans_dict)\n",
    "\n",
    "# 4. Map user\n",
    "\n",
    "state_path = state_directories[3]\n",
    "state_list = os.listdir(state_path)\n",
    "map_user_dict = {\n",
    "                 'State': [], 'Year': [], 'Quarter': [], 'District': [],\n",
    "                 'Registered_users': [], 'App_opens': []\n",
    "                 }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        quarter_path = year_path + year + '/'\n",
    "        quarter_list = os.listdir(quarter_path)\n",
    "        \n",
    "        for quarter in quarter_list:\n",
    "            json_path = quarter_path + quarter\n",
    "            df = pd.read_json(json_path)\n",
    "            \n",
    "            try:\n",
    "                for district, user_data in df['data']['hoverData'].items():\n",
    "                    \n",
    "                    reg_user_count = user_data['registeredUsers']\n",
    "                    app_open_count = user_data['appOpens']\n",
    "                    \n",
    "                    # Appending to map_user_dict\n",
    "                    \n",
    "                    map_user_dict['State'].append(state)\n",
    "                    map_user_dict['Year'].append(year)\n",
    "                    map_user_dict['Quarter'].append(int(quarter.removesuffix('.json')))\n",
    "                    map_user_dict['District'].append(district.removesuffix(' district').title().replace(' And', ' and').replace('andaman', 'Andaman'))\n",
    "                    map_user_dict['Registered_users'].append(reg_user_count)\n",
    "                    map_user_dict['App_opens'].append(app_open_count)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "map_user_df = pd.DataFrame(map_user_dict)\n",
    "\n",
    "# 5. Top Transaction District Wise\n",
    "\n",
    "state_path = state_directories[4]\n",
    "state_list = os.listdir(state_path)\n",
    "top_trans_dist_dict = {\n",
    "                        'State': [], 'Year': [], 'Quarter': [], 'District': [],\n",
    "                        'Transaction_count': [], 'Transaction_amount': []\n",
    "                        }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        quarter_path = year_path + year + '/'\n",
    "        quarter_list = os.listdir(quarter_path)\n",
    "        \n",
    "        for quarter in quarter_list:\n",
    "            json_path = quarter_path + quarter\n",
    "            df = pd.read_json(json_path)\n",
    "            \n",
    "            try:\n",
    "                for district_data in df['data']['districts']:\n",
    "                    \n",
    "                    name = district_data['entityName']\n",
    "                    count = district_data['metric']['count']\n",
    "                    amount = district_data['metric']['amount']\n",
    "                    \n",
    "                    # Appending to top_trans_dist_dict\n",
    "                    \n",
    "                    top_trans_dist_dict['State'].append(state)\n",
    "                    top_trans_dist_dict['Year'].append(year)\n",
    "                    top_trans_dist_dict['Quarter'].append(int(quarter.removesuffix('.json')))                    \n",
    "                    top_trans_dist_dict['District'].append(name.title().replace(' And', ' and').replace('andaman', 'Andaman'))\n",
    "                    top_trans_dist_dict['Transaction_count'].append(count)\n",
    "                    top_trans_dist_dict['Transaction_amount'].append(amount)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "top_trans_dist_df = pd.DataFrame(top_trans_dist_dict)\n",
    "\n",
    "# 6. Top Transaction Pincode Wise\n",
    "\n",
    "state_path = state_directories[4]\n",
    "state_list = os.listdir(state_path)\n",
    "top_trans_pin_dict = {\n",
    "                        'State': [], 'Year': [], 'Quarter': [], 'Pincode': [],\n",
    "                        'Transaction_count': [], 'Transaction_amount': []\n",
    "                        }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        quarter_path = year_path + year + '/'\n",
    "        quarter_list = os.listdir(quarter_path)\n",
    "        \n",
    "        for quarter in quarter_list:\n",
    "            json_path = quarter_path + quarter\n",
    "            df = pd.read_json(json_path)\n",
    "            \n",
    "            try:\n",
    "                for regional_data in df['data']['pincodes']:\n",
    "                    \n",
    "                    name = regional_data['entityName']\n",
    "                    count = regional_data['metric']['count']\n",
    "                    amount = regional_data['metric']['amount']\n",
    "                    \n",
    "                    # Appending to top_trans_pin_dict\n",
    "                    \n",
    "                    top_trans_pin_dict['State'].append(state)\n",
    "                    top_trans_pin_dict['Year'].append(year)\n",
    "                    top_trans_pin_dict['Quarter'].append(int(quarter.removesuffix('.json')))                    \n",
    "                    top_trans_pin_dict['Pincode'].append(name)\n",
    "                    top_trans_pin_dict['Transaction_count'].append(count)\n",
    "                    top_trans_pin_dict['Transaction_amount'].append(amount)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "top_trans_pin_df = pd.DataFrame(top_trans_pin_dict)\n",
    "\n",
    "# 7. Top user district wise\n",
    "\n",
    "state_path = state_directories[5]\n",
    "state_list = os.listdir(state_path)\n",
    "top_user_dist_dict = {\n",
    "                        'State': [], 'Year': [], 'Quarter': [],\n",
    "                        'District': [], 'Registered_users': []\n",
    "                        }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        quarter_path = year_path + year + '/'\n",
    "        quarter_list = os.listdir(quarter_path)\n",
    "        \n",
    "        for quarter in quarter_list:\n",
    "            json_path = quarter_path + quarter\n",
    "            df = pd.read_json(json_path)\n",
    "            \n",
    "            try:\n",
    "                for district_data in df['data']['districts']:\n",
    "                    \n",
    "                    name = district_data['name']\n",
    "                    count = district_data['registeredUsers']\n",
    "                    \n",
    "                    # Appending to top_user_dist_dict\n",
    "                    \n",
    "                    top_user_dist_dict['State'].append(state)\n",
    "                    top_user_dist_dict['Year'].append(year)\n",
    "                    top_user_dist_dict['Quarter'].append(int(quarter.removesuffix('.json')))\n",
    "                    top_user_dist_dict['District'].append(name.title().replace(' And', ' and').replace('andaman', 'Andaman'))\n",
    "                    top_user_dist_dict['Registered_users'].append(count)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "top_user_dist_df = pd.DataFrame(top_user_dist_dict)\n",
    "\n",
    "# 8. Top user Pincode-wise\n",
    "\n",
    "state_path = state_directories[5]\n",
    "state_list = os.listdir(state_path)\n",
    "top_user_pin_dict = {\n",
    "                        'State': [], 'Year': [], 'Quarter': [],\n",
    "                        'Pincode': [], 'Registered_users': []\n",
    "                        }\n",
    "\n",
    "for state in state_list:\n",
    "    year_path = state_path + '/' + state + '/'\n",
    "    year_list = os.listdir(year_path)\n",
    "    \n",
    "    for year in year_list:\n",
    "        quarter_path = year_path + year + '/'\n",
    "        quarter_list = os.listdir(quarter_path)\n",
    "        \n",
    "        for quarter in quarter_list:\n",
    "            json_path = quarter_path + quarter\n",
    "            df = pd.read_json(json_path)\n",
    "            \n",
    "            try:\n",
    "                for regional_data in df['data']['pincodes']:\n",
    "                    \n",
    "                    name = regional_data['name']\n",
    "                    count = regional_data['registeredUsers']\n",
    "                    \n",
    "                    # Appending to top_user_pin_dict\n",
    "                    \n",
    "                    top_user_pin_dict['State'].append(state)\n",
    "                    top_user_pin_dict['Year'].append(year)\n",
    "                    top_user_pin_dict['Quarter'].append(int(quarter.removesuffix('.json')))\n",
    "                    top_user_pin_dict['Pincode'].append(name)\n",
    "                    top_user_pin_dict['Registered_users'].append(count)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "top_user_pin_df = pd.DataFrame(top_user_pin_dict)\n",
    "\n",
    "df_list = [df for df in globals() if isinstance(globals()[df], pd.core.frame.DataFrame) and df.endswith('_df')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c3ccc6",
   "metadata": {},
   "source": [
    "### List of dataframes created so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea5a96c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agg_trans_df',\n",
       " 'agg_user_df',\n",
       " 'map_trans_df',\n",
       " 'map_user_df',\n",
       " 'top_trans_dist_df',\n",
       " 'top_trans_pin_df',\n",
       " 'top_user_dist_df',\n",
       " 'top_user_pin_df']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = [df for df in globals() if isinstance(globals()[df], pd.core.frame.DataFrame) and df.endswith('_df')]\n",
    "df_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706a222e",
   "metadata": {},
   "source": [
    "### Renaming Delhi districts to manage inconsistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaab2964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few district name is mismatched between dfs loaded from pulse and lat_long_df, doing this.\n",
    "\n",
    "def add_suffix_to_districts(df):\n",
    "    if 'District' in df.columns and 'State' in df.columns:\n",
    "        delhi_df = df[df['State'] == 'Delhi']\n",
    "        \n",
    "        districts_to_suffix = [d for d in delhi_df['District'].unique() if d != 'Shahdara']\n",
    "        \n",
    "        df.loc[(df['State'] == 'Delhi') & (df['District'].isin(districts_to_suffix)), 'District'] = df.loc[(df['State'] == 'Delhi') & (df['District'].isin(districts_to_suffix)), 'District'].apply(lambda x: x + ' Delhi' if 'Delhi' not in x else x)\n",
    "\n",
    "    return df\n",
    "\n",
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    add_suffix_to_districts(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4723ab",
   "metadata": {},
   "source": [
    "### Adding Latitude and Longitude columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3818391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lat_long_df = pd.read_csv(r\"C:\\Users\\User\\Desktop\\dist_lat_long.csv\")\n",
    "# st_lat_long_df = pd.read_json(r\"C:\\Users\\User\\Downloads\\india_st.json\")\n",
    "# pin_lat_long_df = pd.read_json(r\"C:\\Users\\User\\Downloads\\archive\\pincode_IN.json\")\n",
    "\n",
    "# merged_dfs = {}  # Dictionary to store merged DataFrames\n",
    "\n",
    "# # for df_name in df_list:\n",
    "# #     df = globals()[df_name]\n",
    "# #     if 'State' and 'District' in df.columns:\n",
    "# #         df = pd.merge(df, lat_long_df, on=['State', 'District'], how='left')\n",
    "# #         globals()[df_name] = df\n",
    "        \n",
    "# # for df_name in df_list:\n",
    "# #     df = globals()[df_name]\n",
    "# #     if 'State' in df.columns:\n",
    "# #         df = pd.merge(df, lat_long_df, on=['State'], how='left')\n",
    "# #         globals()[df_name] = df\n",
    "  \n",
    "\n",
    "# for df_name in df_list:\n",
    "#     df = globals()[df_name]\n",
    "#     if 'State' in df.columns and 'District' in df.columns:\n",
    "#         merged_df = pd.merge(df, lat_long_df, on=['State', 'District'], how='left')\n",
    "#     elif 'State' in df.columns:\n",
    "#         merged_df = pd.merge(df, lat_long_df, on=['State'], how='left')\n",
    "#     else:\n",
    "#         merged_df = df\n",
    "    \n",
    "#     if merged_df[['Latitude', 'Longitude']].isnull().values.any():\n",
    "#         print(f\"Null values found in Latitude or Longitude columns after merging for DataFrame: {df_name}\")\n",
    "#         # Print the rows with null values for debugging\n",
    "#         print(merged_df[merged_df[['Latitude', 'Longitude']].isnull().any(axis=1)])\n",
    "    \n",
    "#     merged_dfs[df_name] = merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb993a83",
   "metadata": {},
   "source": [
    "### Adding Region column to all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aa0c414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_region_column(df):\n",
    "#     state_groups = {\n",
    "#         'Northern Region': ['Jammu and Kashmir', 'Himachal Pradesh', 'Punjab', 'Chandigarh', 'Uttarakhand', 'Ladakh', 'Delhi', 'Haryana'],\n",
    "#         'Central Region': ['Uttar Pradesh', 'Madhya Pradesh', 'Chhattisgarh'],\n",
    "#         'Western Region': ['Rajasthan', 'Gujarat', 'Dadra and Nagar Haveli and Daman and Diu', 'Maharashtra'],\n",
    "#         'Eastern Region': ['Bihar', 'Jharkhand', 'Odisha', 'West Bengal', 'Sikkim'],\n",
    "#         'Southern Region': ['Andhra Pradesh', 'Telangana', 'Karnataka', 'Kerala', 'Tamil Nadu', 'Puducherry', 'Goa', 'Lakshadweep', 'Andaman and Nicobar Islands'],\n",
    "#         'North-Eastern Region': ['Assam', 'Meghalaya', 'Manipur', 'Nagaland', 'Tripura', 'Arunachal Pradesh', 'Mizoram']\n",
    "#     }\n",
    "    \n",
    "#     df['Region'] = df['State'].map({state: region for region, states in state_groups.items() for state in states})\n",
    "#     df['Region'].fillna('Unknown', inplace=True)  # Replace NULL values with 'Unknown'\n",
    "#     return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c43b264b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Iterate over the list of DataFrame names\n",
    "# for df_name in df_list:\n",
    "#     if df_name in globals() and isinstance(globals()[df_name], pd.core.frame.DataFrame):\n",
    "#         globals()[df_name] = add_region_column(globals()[df_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405ad256",
   "metadata": {},
   "source": [
    "### Columnwise null-count and duplicated_rows-count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8a6216c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agg_trans_df:\n",
      "Null count: \n",
      "State                 0\n",
      "Year                  0\n",
      "Quarter               0\n",
      "Transaction_type      0\n",
      "Transaction_count     0\n",
      "Transaction_amount    0\n",
      "dtype: int64\n",
      "Duplicated rows count: \n",
      "0\n",
      "(3594, 6)\n",
      "\n",
      " _________________________ \n",
      "\n",
      "agg_user_df:\n",
      "Null count: \n",
      "State                0\n",
      "Year                 0\n",
      "Quarter              0\n",
      "Brand                0\n",
      "Transaction_count    0\n",
      "Percentage           0\n",
      "dtype: int64\n",
      "Duplicated rows count: \n",
      "0\n",
      "(6732, 6)\n",
      "\n",
      " _________________________ \n",
      "\n",
      "map_trans_df:\n",
      "Null count: \n",
      "State                 0\n",
      "Year                  0\n",
      "Quarter               0\n",
      "District              0\n",
      "Transaction_count     0\n",
      "Transaction_amount    0\n",
      "dtype: int64\n",
      "Duplicated rows count: \n",
      "0\n",
      "(14636, 6)\n",
      "\n",
      " _________________________ \n",
      "\n",
      "map_user_df:\n",
      "Null count: \n",
      "State               0\n",
      "Year                0\n",
      "Quarter             0\n",
      "District            0\n",
      "Registered_users    0\n",
      "App_opens           0\n",
      "dtype: int64\n",
      "Duplicated rows count: \n",
      "0\n",
      "(14640, 6)\n",
      "\n",
      " _________________________ \n",
      "\n",
      "top_trans_dist_df:\n",
      "Null count: \n",
      "State                 0\n",
      "Year                  0\n",
      "Quarter               0\n",
      "District              0\n",
      "Transaction_count     0\n",
      "Transaction_amount    0\n",
      "dtype: int64\n",
      "Duplicated rows count: \n",
      "0\n",
      "(5920, 6)\n",
      "\n",
      " _________________________ \n",
      "\n",
      "top_trans_pin_df:\n",
      "Null count: \n",
      "State                 0\n",
      "Year                  0\n",
      "Quarter               0\n",
      "Pincode               2\n",
      "Transaction_count     0\n",
      "Transaction_amount    0\n",
      "dtype: int64\n",
      "Duplicated rows count: \n",
      "0\n",
      "(7139, 6)\n",
      "\n",
      " _________________________ \n",
      "\n",
      "top_user_dist_df:\n",
      "Null count: \n",
      "State               0\n",
      "Year                0\n",
      "Quarter             0\n",
      "District            0\n",
      "Registered_users    0\n",
      "dtype: int64\n",
      "Duplicated rows count: \n",
      "0\n",
      "(5920, 5)\n",
      "\n",
      " _________________________ \n",
      "\n",
      "top_user_pin_df:\n",
      "Null count: \n",
      "State               0\n",
      "Year                0\n",
      "Quarter             0\n",
      "Pincode             0\n",
      "Registered_users    0\n",
      "dtype: int64\n",
      "Duplicated rows count: \n",
      "0\n",
      "(7140, 5)\n",
      "\n",
      " _________________________ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    print(f\"{df_name}:\")\n",
    "    print(f\"Null count: \\n{df.isnull().sum()}\")\n",
    "    print(f\"Duplicated rows count: \\n{df.duplicated().sum()}\")\n",
    "    print(df.shape)\n",
    "    print(\"\\n\", 25 * \"_\", \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8e1363",
   "metadata": {},
   "source": [
    "### Understanding the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4f8ed0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATAFRAME INFO:\n",
      "\n",
      "agg_trans_df:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3594 entries, 0 to 3593\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   State               3594 non-null   object \n",
      " 1   Year                3594 non-null   object \n",
      " 2   Quarter             3594 non-null   int64  \n",
      " 3   Transaction_type    3594 non-null   object \n",
      " 4   Transaction_count   3594 non-null   int64  \n",
      " 5   Transaction_amount  3594 non-null   float64\n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 168.6+ KB\n",
      "\n",
      " _____________________________________________ \n",
      "\n",
      "agg_user_df:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6732 entries, 0 to 6731\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   State              6732 non-null   object \n",
      " 1   Year               6732 non-null   object \n",
      " 2   Quarter            6732 non-null   int64  \n",
      " 3   Brand              6732 non-null   object \n",
      " 4   Transaction_count  6732 non-null   int64  \n",
      " 5   Percentage         6732 non-null   float64\n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 315.7+ KB\n",
      "\n",
      " _____________________________________________ \n",
      "\n",
      "map_trans_df:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14636 entries, 0 to 14635\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   State               14636 non-null  object \n",
      " 1   Year                14636 non-null  object \n",
      " 2   Quarter             14636 non-null  int64  \n",
      " 3   District            14636 non-null  object \n",
      " 4   Transaction_count   14636 non-null  int64  \n",
      " 5   Transaction_amount  14636 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 686.2+ KB\n",
      "\n",
      " _____________________________________________ \n",
      "\n",
      "map_user_df:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   State             14640 non-null  object\n",
      " 1   Year              14640 non-null  object\n",
      " 2   Quarter           14640 non-null  int64 \n",
      " 3   District          14640 non-null  object\n",
      " 4   Registered_users  14640 non-null  int64 \n",
      " 5   App_opens         14640 non-null  int64 \n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 686.4+ KB\n",
      "\n",
      " _____________________________________________ \n",
      "\n",
      "top_trans_dist_df:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5920 entries, 0 to 5919\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   State               5920 non-null   object \n",
      " 1   Year                5920 non-null   object \n",
      " 2   Quarter             5920 non-null   int64  \n",
      " 3   District            5920 non-null   object \n",
      " 4   Transaction_count   5920 non-null   int64  \n",
      " 5   Transaction_amount  5920 non-null   float64\n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 277.6+ KB\n",
      "\n",
      " _____________________________________________ \n",
      "\n",
      "top_trans_pin_df:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7139 entries, 0 to 7138\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   State               7139 non-null   object \n",
      " 1   Year                7139 non-null   object \n",
      " 2   Quarter             7139 non-null   int64  \n",
      " 3   Pincode             7137 non-null   object \n",
      " 4   Transaction_count   7139 non-null   int64  \n",
      " 5   Transaction_amount  7139 non-null   float64\n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 334.8+ KB\n",
      "\n",
      " _____________________________________________ \n",
      "\n",
      "top_user_dist_df:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5920 entries, 0 to 5919\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   State             5920 non-null   object\n",
      " 1   Year              5920 non-null   object\n",
      " 2   Quarter           5920 non-null   int64 \n",
      " 3   District          5920 non-null   object\n",
      " 4   Registered_users  5920 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 231.4+ KB\n",
      "\n",
      " _____________________________________________ \n",
      "\n",
      "top_user_pin_df:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7140 entries, 0 to 7139\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   State             7140 non-null   object\n",
      " 1   Year              7140 non-null   object\n",
      " 2   Quarter           7140 non-null   int64 \n",
      " 3   Pincode           7140 non-null   object\n",
      " 4   Registered_users  7140 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 279.0+ KB\n",
      "\n",
      " _____________________________________________ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('DATAFRAME INFO:\\n')\n",
    "\n",
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    print(df_name + ':\\n')\n",
    "    df.info()\n",
    "    print(\"\\n\", 45 * \"_\", \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f93073e",
   "metadata": {},
   "source": [
    "### Dropping rows with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "701190e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State                 0\n",
       "Year                  0\n",
       "Quarter               0\n",
       "Pincode               0\n",
       "Transaction_count     0\n",
       "Transaction_amount    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'top_trans_pin_df' seems to have two null values and they are not of significant proportion so dropping them;\n",
    "\n",
    "top_trans_pin_df.dropna(axis = 'index', inplace = True)\n",
    "top_trans_pin_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72b9e93",
   "metadata": {},
   "source": [
    "### Changing datatype across all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79d1e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year column in all the dataframes seems to be of object dtype so changing it to int object so as to push into MySQL as year;\n",
    "\n",
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    df['Year'] = df['Year'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdf1a3e",
   "metadata": {},
   "source": [
    "### Outlier count across all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f2a539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything seems to be alright as far as dtypes and nullvalues are concerned so checking for outliers\n",
    "# Function to check for outliers\n",
    "\n",
    "def count_outliers(df):\n",
    "    outliers = {}\n",
    "    for col in df.select_dtypes(include=[np.number]).columns:\n",
    "        if col in ['Transaction_count', 'Transaction_amount']:\n",
    "            q1 = df[col].quantile(0.25)\n",
    "            q3 = df[col].quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "            upper_bound = q3 + (1.5 * iqr)\n",
    "            lower_bound = q1 - (1.5 * iqr)\n",
    "            outliers[col] = len(df[(df[col] > upper_bound) | (df[col] < lower_bound)])\n",
    "        else:\n",
    "            continue\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f58981d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTLIER COUNT ACROSS DATAFRAMES:\n",
      "\n",
      "agg_trans_df :\n",
      "\n",
      " {'Transaction_count': 652, 'Transaction_amount': 660} \n",
      "\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "agg_user_df :\n",
      "\n",
      " {'Transaction_count': 893} \n",
      "\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "map_trans_df :\n",
      "\n",
      " {'Transaction_count': 1811, 'Transaction_amount': 1771} \n",
      "\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "top_trans_dist_df :\n",
      "\n",
      " {'Transaction_count': 734, 'Transaction_amount': 743} \n",
      "\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "top_trans_pin_df :\n",
      "\n",
      " {'Transaction_count': 999, 'Transaction_amount': 995} \n",
      "\n",
      "\n",
      " _______________________________________________________ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('OUTLIER COUNT ACROSS DATAFRAMES:\\n')\n",
    "\n",
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    outliers = count_outliers(df)\n",
    "    if len(outliers) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        print(df_name, \":\\n\\n\", outliers, \"\\n\")\n",
    "        print(\"\\n\", 55 * \"_\", \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86143afd",
   "metadata": {},
   "source": [
    "### Unique value count across all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4418fe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check for unique value counts and print if count less than 10;\n",
    "\n",
    "def unique_value_count(df, exclude_cols=[]):\n",
    "    for col in df.columns:\n",
    "        if col in exclude_cols:\n",
    "            continue\n",
    "        unique_vals = df[col].nunique()\n",
    "        print(f\"{col}: {unique_vals} unique values\")\n",
    "        if unique_vals < 10:\n",
    "            print(df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4c37756",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNIQUE VALUE COUNT ACROSS DATAFRAMES; \n",
      "\n",
      "agg_trans_df :\n",
      "\n",
      "Transaction_type: 5 unique values\n",
      "['Recharge & bill payments' 'Peer-to-peer payments' 'Merchant payments'\n",
      " 'Financial Services' 'Others']\n",
      "Transaction_count: 3548 unique values\n",
      "Transaction_amount: 3594 unique values\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "agg_user_df :\n",
      "\n",
      "Brand: 20 unique values\n",
      "Transaction_count: 6501 unique values\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "map_trans_df :\n",
      "\n",
      "District: 727 unique values\n",
      "Transaction_count: 14566 unique values\n",
      "Transaction_amount: 14636 unique values\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "map_user_df :\n",
      "\n",
      "District: 727 unique values\n",
      "Registered_users: 14351 unique values\n",
      "App_opens: 10977 unique values\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "top_trans_dist_df :\n",
      "\n",
      "District: 368 unique values\n",
      "Transaction_count: 5910 unique values\n",
      "Transaction_amount: 5920 unique values\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "top_trans_pin_df :\n",
      "\n",
      "Pincode: 746 unique values\n",
      "Transaction_count: 7083 unique values\n",
      "Transaction_amount: 7137 unique values\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "top_user_dist_df :\n",
      "\n",
      "District: 313 unique values\n",
      "Registered_users: 5874 unique values\n",
      "\n",
      " _______________________________________________________ \n",
      "\n",
      "top_user_pin_df :\n",
      "\n",
      "Pincode: 426 unique values\n",
      "Registered_users: 6882 unique values\n",
      "\n",
      " _______________________________________________________ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('UNIQUE VALUE COUNT ACROSS DATAFRAMES; \\n')\n",
    "\n",
    "for df_name in df_list:\n",
    "    df = globals()[df_name]\n",
    "    print(df_name, \":\\n\")\n",
    "    unique_value_count(df, exclude_cols = ['State', 'Year', 'Quarter', 'Percentage'])\n",
    "    print(\"\\n\", 55 * \"_\", \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41573072",
   "metadata": {},
   "source": [
    "### Creating CSV files out of the refined dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed82e78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_dfs_as_csv(df_list):\n",
    "#     subfolder = 'Miscellaneous'\n",
    "#     if not os.path.exists(subfolder):\n",
    "#         os.makedirs(subfolder)\n",
    "        \n",
    "#     for df_name in df_list:\n",
    "#         df = globals()[df_name]\n",
    "#         file_path = os.path.join(subfolder, df_name.replace('_df', '') + '.csv')\n",
    "#         df.to_csv(file_path, index=False)\n",
    "\n",
    "# # Calling function to execute\n",
    "\n",
    "# save_dfs_as_csv(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c58b1e",
   "metadata": {},
   "source": [
    "# SQL part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20041a7a",
   "metadata": {},
   "source": [
    "### Establishing connection and creating cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "719d506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = mysql.connector.connect(host = 'localhost', \n",
    "                               user = 'root',\n",
    "                               password = 'rakshita'\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc0bb61",
   "metadata": {},
   "source": [
    "### Database creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79dd5240",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"DROP DATABASE IF EXISTS phonepe_pulse\")\n",
    "\n",
    "cursor.execute(\"CREATE DATABASE phonepe_pulse\")\n",
    "\n",
    "cursor.execute(\"USE phonepe_pulse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe9c60e",
   "metadata": {},
   "source": [
    "### Creating tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08e4e1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('''CREATE TABLE agg_trans (\n",
    "                    State VARCHAR(255),\n",
    "                    Year YEAR,\n",
    "                    Quarter INTEGER,\n",
    "                    Transaction_type VARCHAR(255),\n",
    "                    Transaction_count INTEGER,\n",
    "                    Transaction_amount FLOAT,                   \n",
    "                    PRIMARY KEY (State(255), Year, Quarter, Transaction_type(255))\n",
    "                 )''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE agg_user (\n",
    "                    State VARCHAR(255),\n",
    "                    Year YEAR,\n",
    "                    Quarter INTEGER,\n",
    "                    Brand VARCHAR(255),\n",
    "                    Transaction_count INTEGER,\n",
    "                    Percentage FLOAT,                    \n",
    "                    PRIMARY KEY (State(255), Year, Quarter, Brand(255))\n",
    "                 )''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE map_trans (\n",
    "                    State VARCHAR(255),\n",
    "                    Year YEAR,\n",
    "                    Quarter INTEGER,\n",
    "                    District VARCHAR(255),\n",
    "                    Transaction_count INTEGER,\n",
    "                    Transaction_amount FLOAT,                    \n",
    "                    PRIMARY KEY (State(255), Year, Quarter, District(255))\n",
    "                 )''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE map_user (\n",
    "                    State VARCHAR(255),\n",
    "                    Year YEAR,\n",
    "                    Quarter INTEGER,\n",
    "                    District VARCHAR(255),\n",
    "                    Registered_users INTEGER,\n",
    "                    App_opens INTEGER,\n",
    "                    PRIMARY KEY (State(255), Year, Quarter, District(255))\n",
    "                 )''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE top_trans_dist (\n",
    "                    State VARCHAR(255),\n",
    "                    Year YEAR,\n",
    "                    Quarter INTEGER,\n",
    "                    District VARCHAR(255),\n",
    "                    Transaction_count INTEGER,\n",
    "                    Transaction_amount FLOAT,                    \n",
    "                    PRIMARY KEY (State(255), Year, Quarter, District(255))\n",
    "                 )''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE top_trans_pin (\n",
    "                    State VARCHAR(255),\n",
    "                    Year YEAR,\n",
    "                    Quarter INTEGER,\n",
    "                    Pincode VARCHAR(255),\n",
    "                    Transaction_count INTEGER,\n",
    "                    Transaction_amount FLOAT,                    \n",
    "                    PRIMARY KEY (State(255), Year, Quarter, Pincode(255))\n",
    "                 )''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE top_user_dist (\n",
    "                    State VARCHAR(255),\n",
    "                    Year YEAR,\n",
    "                    Quarter INTEGER,\n",
    "                    District VARCHAR(255),\n",
    "                    Registered_users INTEGER,\n",
    "                    PRIMARY KEY (State(255), Year, Quarter, District(255))\n",
    "                 )''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE top_user_pin (\n",
    "                    State VARCHAR(255),\n",
    "                    Year YEAR,\n",
    "                    Quarter INTEGER,\n",
    "                    Pincode VARCHAR(255),\n",
    "                    Registered_users INTEGER,\n",
    "                    PRIMARY KEY (State(255), Year, Quarter, Pincode(255))\n",
    "                 )''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90a13db",
   "metadata": {},
   "source": [
    "### Pushing data into MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e1fd1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_data_into_mysql(conn, cursor, dfs, table_columns):\n",
    "    try:\n",
    "        for table_name, df in dfs.items():\n",
    "            if table_name in table_columns:\n",
    "                columns = table_columns[table_name]\n",
    "                placeholders = ', '.join(['%s'] * len(columns))\n",
    "                query = f\"INSERT INTO {table_name} ({', '.join(columns)}) VALUES ({placeholders})\"\n",
    "                for _, row in df.iterrows():\n",
    "                    data = tuple(row[column] for column in columns)\n",
    "                    cursor.execute(query, data)\n",
    "                conn.commit()\n",
    "                print(f\"Data successfully pushed into MySQL table: {table_name}\")\n",
    "            else:\n",
    "                print(f\"No column information found for table: {table_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while pushing data into MySQL tables: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e16893e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping my_sql tables to pandas dataframes that we have created earlier\n",
    "\n",
    "dfs = {\n",
    "    'agg_trans': agg_trans_df,\n",
    "    'agg_user': agg_user_df,\n",
    "    'map_trans': map_trans_df,\n",
    "    'map_user': map_user_df,\n",
    "    'top_trans_dist': top_trans_dist_df,\n",
    "    'top_trans_pin': top_trans_pin_df,\n",
    "    'top_user_dist': top_user_dist_df,\n",
    "    'top_user_pin': top_user_pin_df\n",
    "}\n",
    "\n",
    "# Mapping table name to associated columns for each table\n",
    "\n",
    "table_columns = {\n",
    "    'agg_trans': list(agg_trans_df.columns),\n",
    "    'agg_user': list(agg_user_df.columns),\n",
    "    'map_trans': list(map_trans_df.columns),\n",
    "    'map_user': list(map_user_df.columns),\n",
    "    'top_trans_dist': list(top_trans_dist_df.columns),\n",
    "    'top_trans_pin': list(top_trans_pin_df.columns),\n",
    "    'top_user_dist': list(top_user_dist_df.columns),\n",
    "    'top_user_pin': list(top_user_pin_df.columns)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7baa9ff1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully pushed into MySQL table: agg_trans\n",
      "Data successfully pushed into MySQL table: agg_user\n",
      "Data successfully pushed into MySQL table: map_trans\n",
      "Data successfully pushed into MySQL table: map_user\n",
      "Data successfully pushed into MySQL table: top_trans_dist\n",
      "Data successfully pushed into MySQL table: top_trans_pin\n",
      "Data successfully pushed into MySQL table: top_user_dist\n",
      "Data successfully pushed into MySQL table: top_user_pin\n"
     ]
    }
   ],
   "source": [
    "push_data_into_mysql(conn, cursor, dfs, table_columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
